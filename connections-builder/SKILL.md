---
name: connections-builder
description: Analyze service integration maps and build a unified connections file showing all cross-service flows
triggers:
  - "build connections"
  - "create connections map"
  - "analyze service connections"
  - "generate _connections.yaml"
---

# Connections Builder

Analyze all service integration YAML files and produce a unified connections map that shows how services interact through queues, HTTP calls, and webhooks.

## Goal

Produce a single file:
- **`_connections.yaml`** - Unified map of all cross-service connections

## Input

All files matching: `docs/tech/flows/technical/{service}.yaml`

Generated by the `service-integration-mapper` skill.

## Output Location

```
docs/tech/flows/technical/_connections.yaml
```

## Output Philosophy

- **Match produces ↔ consumes**: Find where one service's output is another's input
- **Trace complete flows**: Show the full path from trigger to final outcome
- **Identify gaps**: Mark `[UNKNOWN]` for referenced but undocumented services
- **Enable visualization**: Structure supports generating sequence diagrams

---

## Output Schema

```yaml
# Service Connections Map
# Auto-generated: {date}
#
# Maps how services connect based on their produces/consumes definitions.
# [UNKNOWN] = involves a service not yet documented

# ============================================================
# QUEUE FLOWS
# ============================================================

queues:

  - queue: {QUEUE_NAME}
    message_type: {MessageTypeName}
    publisher: {service-name}
    consumer: {service-name} | [UNKNOWN] {service-name}
    handler: {handlerFunctionName}
    trigger: {what causes publish}
    outcome:
      external_call: {service} ({action})
      database_write: {table}
      cache_write: {Redis key pattern}
      analytics: {destination} ({event_type})
      queue_publish: {next queue if chained}

  # For queues with multiple consumers
  - queue: {QUEUE_NAME}
    message_type: {MessageTypeName}
    publisher: {service-name}
    consumers:
      - service: {service-name}
        queue_alias: {CONSUMER_QUEUE_NAME if different}
        handler: {handlerFunctionName}
        outcome:
          external_call: {service}

      - service: [UNKNOWN] {service-name}
        queue_alias: {queue name}
        purpose: {inferred purpose}
        note: {why unknown}

# ============================================================
# HTTP FLOWS
# ============================================================

http:

  {source}_to_{target}:
    - flow: {Human readable flow name}
      verb: GET | POST | PUT | PATCH | DELETE
      path: /api/endpoint
      source: {calling service} | clients
      handler: {handling service}
      triggers_chain:  # Optional: for flows that trigger other calls
        - step: 1
          call: {service}
          verb: POST
          path: /api/...
          purpose: {why}
        - step: 2
          outcome: {what happens}
      outcome:
        database_write: {table}
        database_read: {table}
        queue_publish: {queue}
        external_call: {service}
        cache_write: {pattern}

# ============================================================
# WEBHOOK FLOWS
# ============================================================

webhooks:

  {source}_to_{target}:
    - flow: {Human readable name}
      verb: POST
      path: /webhook/path
      source: {External service - Stripe | Twilio | etc}
      handler: {service-name}
      payload:
        field: type
      outcome:
        cache_read: {pattern}
        analytics: {destination}
        database_write: {table}

# ============================================================
# END-TO-END FLOWS
# ============================================================

e2e_flows:

  - name: {Business flow name}
    description: {What this flow accomplishes}
    steps:
      - seq: 1
        type: http | queue | webhook | external | database | cache | analytics
        source: {who initiates}
        target: {who receives}
        path: {endpoint if http}
        queue: {queue if queue}
        action: {what happens}
        note: {optional context}

      - seq: 2
        type: ...

# ============================================================
# UNKNOWN CONNECTIONS
# ============================================================

unknown:

  - service: {service-name}
    referenced_by:
      - {service} calls {verb} {path}
      - {service} publishes to {queue}
    action_needed: Create {service}.yaml
```

---

## Matching Algorithm

### Step 1: Load All Service Files

```bash
ls docs/tech/flows/technical/*.yaml | grep -v _connections
```

Parse each file into memory.

### Step 2: Build Queue Connections

For each service file:
1. Collect all `produces.queues` entries
2. Collect all `consumes.queues` entries

Match by queue name:
```
Service A: produces.queues[].queue = "ORDER_CREATED_QUEUE_URL"
Service B: consumes.queues[].queue = "ORDER_CREATED_QUEUE_URL"
→ Connection: A publishes, B consumes
```

If a queue is published but no consumer found:
```yaml
consumer: "[UNKNOWN]"
note: "No service documents consuming this queue"
```

If a queue is consumed but no publisher found:
```yaml
publisher: "[UNKNOWN]"
note: "No service documents publishing to this queue"
```

### Step 3: Build HTTP Connections

For each service file:
1. Collect all `produces.http_calls` entries
2. Collect all `consumes.http` entries
3. Collect all `produces.http_proxy` entries (gateway services)

Match by target + path pattern:
```
Service A: produces.http_calls[].target = "inventory-service"
           produces.http_calls[].path = "/api/inventory/:productId/check"
Service B: consumes.http[].path = "/api/inventory/:productId/check"
           (where B = inventory-service)
→ Connection: A calls B
```

For proxy routes:
```
Gateway: produces.http_proxy[].path = "/api/orders/*"
         produces.http_proxy[].target = "order-service"
→ All /api/orders/* traffic flows: clients → Gateway → order-service
```

### Step 4: Build Webhook Connections

For each service file:
1. Collect all `consumes.webhooks` entries

Group by source:
```yaml
webhooks:
  stripe_to_payment:
    - flow: Payment Status Update
      ...
  shipping_provider_to_fulfillment:
    - flow: Shipment Tracking Update
      ...
```

### Step 5: Trace Outcomes

For each connection, trace what happens next:

1. Look at the consumer's handler
2. Check if it produces:
   - `external_calls` → Add to outcome
   - `database_writes` → Add to outcome
   - `cache_writes` → Add to outcome
   - `analytics` → Add to outcome
   - `queues` → Add to outcome (creates chain)

### Step 6: Build End-to-End Flows

Identify major flows by:
1. Starting from client-facing endpoints
2. Following the chain of calls/queues/webhooks
3. Ending at final outcomes (external call, database write, analytics)

Common patterns to look for:
- HTTP → Queue → External Call → Webhook → Analytics
- HTTP → HTTP → Database Write
- Webhook → Cache Read → Analytics

### Step 7: Identify Unknown Services

Collect all referenced services that don't have their own YAML file:
```yaml
unknown:
  - service: recommendation-service
    referenced_by:
      - order-service calls POST /api/recommendations/for-customer
      - inventory-service publishes to LOW_STOCK_ALERT_QUEUE_URL
    action_needed: Create recommendation-service.yaml
```

---

## Execution Instructions

### Step 1: List Available Service Files

```bash
ls docs/tech/flows/technical/*.yaml | grep -v _connections
```

### Step 2: Read All Service Files

Load each file and extract:
- Service name
- All `consumes` entries
- All `produces` entries
- All `data` entries

### Step 3: Build Queues Section

For each unique queue name found:
1. Find publisher (from `produces.queues`)
2. Find consumer(s) (from `consumes.queues`)
3. Get handler name from consumer
4. Get trigger from publisher
5. Trace outcomes from consumer's `produces`

### Step 4: Build HTTP Section

Group by direction: `{source}_to_{target}`

For each HTTP call:
1. Get verb + path from `produces.http_calls`
2. Match to `consumes.http` in target service
3. Get purpose from either side
4. Trace outcomes from handler's `produces`

### Step 5: Build Webhooks Section

Group by external source: `{external}_to_{service}`

For each webhook:
1. Get details from `consumes.webhooks`
2. Trace outcomes from handler's `produces`

### Step 6: Build E2E Flows

Identify 3-5 key business flows:
1. Start from significant client endpoints
2. Follow all downstream calls
3. Document each step with seq number

### Step 7: Build Unknown Section

Collect all services referenced but not documented:
1. From `produces.http_calls[].target`
2. From `consumes.queues[].source`
3. From any `[UNKNOWN]` markers

### Step 8: Write Output

Save to: `docs/tech/flows/technical/_connections.yaml`

---

## Quality Checklist

Before finalizing, verify:

- [ ] Every queue has both publisher and consumer (or `[UNKNOWN]`)
- [ ] HTTP flows match actual service endpoints
- [ ] Webhooks grouped by external source
- [ ] E2E flows are complete (no dangling steps)
- [ ] All `[UNKNOWN]` services listed in unknown section
- [ ] Outcomes traced for each connection
- [ ] No orphan queues (published but never consumed)
- [ ] No phantom queues (consumed but never published)

---

## Example

**Input files:**

`api-gateway.yaml`:
```yaml
produces:
  queues:
    - queue: ORDER_CREATED_QUEUE_URL
      message_type: OrderCreatedEvent
      trigger: POST /api/orders/checkout
```

`fulfillment-service.yaml`:
```yaml
consumes:
  queues:
    - queue: ORDER_CREATED_QUEUE_URL
      message_type: OrderCreatedEvent
      source: api-gateway
      handler: handleOrderCreated

produces:
  external_calls:
    - service: ShipStation
      action: Create shipment
      trigger: ORDER_CREATED_QUEUE_URL consumed

  cache_writes:
    - cache: Redis
      key_pattern: "shipment:{orderId}"
      trigger: Shipment created

  analytics:
    - destination: BigQuery
      event_type: order_fulfilled
```

**Output (_connections.yaml excerpt):**
```yaml
queues:
  - queue: ORDER_CREATED_QUEUE_URL
    message_type: OrderCreatedEvent
    publisher: api-gateway
    consumer: fulfillment-service
    handler: handleOrderCreated
    trigger: POST /api/orders/checkout
    outcome:
      external_call: ShipStation (Create shipment)
      cache_write: Redis (shipment:{orderId})
      analytics: BigQuery (order_fulfilled)
```

---

## Notes

- Run this skill after all relevant services have been mapped with service-integration-mapper
- Re-run when new service YAML files are added
- The `unknown` section serves as a TODO list for documentation gaps
- E2E flows are valuable for onboarding and debugging
- Output is designed to be consumed by flow-diagram-generator skill
